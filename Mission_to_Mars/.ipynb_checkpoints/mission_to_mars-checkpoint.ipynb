{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mission to Mars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BeautifulSoup, Pandas, and Requests/Splinter, will perform a web scraping of the following:\n",
    "- [NASA Mars News Sites](https://mars.nasa.gov/news/) to collect the latest News Title and Paragraph Text and store for later use;\n",
    "- [JPL Mars Space Images](https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars) to collect the full size .jpg of the featured image;\n",
    "- [Mars Weather Twitter](https://twitter.com/marswxreport?lang=en) to scrape the latest Mars weather tweets from the page;\n",
    "- [Mars Facts page](https://space-facts.com/mars/) - using Pandas to scrape table containing facts about the planet such as Diameter, Mass, etc.; and\n",
    "- [USGS Astrology Site](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to collect high resolution impages for each of Mar's hemispheres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Splinter configuration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use if os join doesn't work: '../resources/chromedriver.exe'\n",
    "executable_path = {'executable_path': os.path.join(\"..\",\"Resources\",\"chromedriver.exe\")}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define variables for each URL to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_nasa = 'https://mars.nasa.gov/news/'\n",
    "url_jpl = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "url_weather = 'https://twitter.com/marswxreport?lang=en'\n",
    "url_facts = 'https://space-facts.com/mars/'\n",
    "url_USGS = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA Mars News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pass through nasa url variable to browser to visit site and establish variables to capture underlying HTML and pass back to BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(url_nasa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Establish variables to capture first news title and associated p tags for latest news info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = soup.find('div', attrs={'class': 'content_title'})\n",
    "news_title = div.find('a').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_p = soup.find('div', attrs={'class': 'article_teaser_body'})\n",
    "#news_p = div.find.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Featured Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pass through jpl url variable to browser to visit site and establish variables to capture underlying HTML and pass back to BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(url_jpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Click through full size image button feature image and then establish variable to capture full size Feature Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to click full size image first and then scrape - go back to class activity to find instruction on clicking but this is my first pass and will also need to join page url to src to complete full url so hopefully os works on urls\n",
    "feature_image_button = driver.find_element_by_id('full_image')\n",
    "feature_image_button.click()\n",
    "feature_image = soup.find('img')\n",
    "featured_image_url = os.path.join(url_jpl, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pass through weather url variable to browser to visit site and establish variables to capture underlying HTML and pass back to BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(url_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Establish variables to capture first news title and associated p tags for latest news info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = soup.find('div', attrs={'class': 'js-tweet-text-container'})\n",
    "mars_weather = div.find('p').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Pandas read_html function using the facts url variable to brower to visit site and capture table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html(url_facts)\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tables[0]\n",
    "df.columns = ['Metric', 'Value']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Pandas to_html function convert to HTML table string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres using USGS Astrology Site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pass through USGS url variable to browser to visit site and establish variables to capture underlying HTML and pass back to BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(url_USGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using a for loop, identify the div class containing the hemisphere data and link to image download and store as dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls = []\n",
    "div = soup.find_all('div', attrs={'class': 'description'})\n",
    "\n",
    "#hemisphere_links = []\n",
    "#link = soup.find_all('a', attrs={'class': 'itemLink product-item'}, href=True)[i]\n",
    "\n",
    "for in range (0,3):\n",
    "    title = div.find_all('h3')[i].text\n",
    "    link = div.find_all('a', attrs={'class': 'itemLink product-item'})[i].get('href')\n",
    "    browser.visit(link)\n",
    "    download = soup.find('div', attrs={'class': 'downloads'})\n",
    "    img_url = download.find_all('a')[1].get('href')\n",
    "    hemisphere_image_urls.append({'title': title, 'img_url': img_url})\n",
    "    browser.visit(url_USGS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
